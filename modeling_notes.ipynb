{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Notes: ##\n",
    "#### Deep Approcimate Shapely Propagation ####\n",
    "\n",
    "Shapley values:\n",
    "- No hyper-parameters, except a baseline is require. \n",
    "Axioms that Shapley values satisfy:\n",
    "##### Completeness: ##### \n",
    "When attributions sum up to the difference between the value of the function evaluated at the input and the value of the function evaluated at the baseline : sum = f(x) - f(0).\n",
    "##### Null player: #####\n",
    "If the function does not depend on some variable, the attribution for the variable would be zero.\n",
    "##### Symmetry: #####\n",
    "If the function depends on two variables but not necessarily on their order, then the attribution assigned to them is the same every time the input and the baseline provides the same values for these variables.\n",
    "##### Linearity: ##### \n",
    "If the function can be seen as a linear combination of the functions of two sub-networks, then any attribution should also be a linear combination, with the same weights, of the attributions computed on the sub-networks.\n",
    "##### Continuity ##### \n",
    "The attributions for two identical inputs should be identical as well.\n",
    "##### Implementation Invariance ##### \n",
    "Two networks are said to be functionally equivalent if their outputs are equal for all inputs, despite having very different implementations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Approximate Shapley Propagation\n",
    "- A pretrubation-based method that can reliably approximate Shapley values in DNNs with a polynomial number of perturbation steps.\n",
    "- Computing the Shapley values with respect to ont output unit of a neural network whose overall function is the composition of several of layers with a non-linear function.\n",
    "- The Shapley value of an input feature is given by its marginal contribution to all possible 2^(N-1) conditions that can be made out of the remaining features. Instead of enumerating each of them, we can compute the expected contribution to get the average value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
